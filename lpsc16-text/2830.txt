2830.PDF
WHAT THE CAMERA DOESN'T SEE: OCCLUSIONS AND ORTHORECTIFICATION.  T.J. Wilson1, K.L. Edmundson1, T.L. Becker1, and Kestay, L.1 1Astrogeology Science Center, United States Geological Survey, Flagstaff AZ, USA, 86001  (tjwilson@usgs.gov)  Introduction: Orthorectification, an essential task in terrestrial and extraterrestrial photogrammetry, removes the effects of image perspective and relief displacement. Images are projected using a digital elevation model (DEM) such that the resulting orthophoto has uniform scale and resembles a planimetric map. Basic approaches to orthorectification are described in [1]. The process as implemented in the USGS Integrated Software for Imagers and Spectrometers (ISIS [2]) planetary cartography package is described in [3]. Surface features (natural or otherwise) may hide or occlude areas behind them from the camera. In terrestrial urban mapping, buildings create occlusions. In extraterrestrial applications they may result from craters, crater rims, mountains, and highly irregular bodies (e.g (25143) Itokawa, (433) Eros). It is well-known that occlusions are problematic in the process of orthorectification [4]. In Figure 1 we illustrate the problem with a highly oblique image and a profile of a central peak crater (though occlusions are not restricted to oblique imagery). The look vector from the raw image plane intersects the surface at multiple locations (A,B,C). B and C are not visible to the camera. A naïve orthorectification approach will incorrectly project the raw image pixel corresponding to A to the locations for B and C in the orthophoto. A proper implementation must recognize 1) that of the three surface intersections, the one closest to the camera (A) is valid; and 2) that B and C are occluded and leave their corresponding locations in the orthophoto empty. We illustrate further with a highly oblique image (40°S) of the Moon acquired with the Apollo 15 Metric Camera [5]. The overlay in the raw photo (Figure 2, top) is an attempt to visualize the occluded portion of a crater. In the orthorectified version of this crater (Figure 2, bottom), we see smaller craters that are visible to the camera incorrectly projected multiple times into the occluded region. Possible Solutions: Any algorithm that handles the occlusion problem must contend with two issues as described in [4]: . All surface points visible in the direction of pro Figure 1: The occlusion problem in cross-section. The raw image pixel for A is projected to A, B and C in the orthophoto, though B and C are not visible in the raw image.   Figure 2: Top - Portion of Apollo MC 40°S oblique photo AS15-M-2497 from orbit 71 (note this image is rotated from its original orientation such that south is approximately up or toward the limb); highlighted crater at ~33.6°S latitude, 97.03°E longitude. Bottom - Projected image; green box - correctly projected location of small craters; red boxes - same craters repeatedly projected incorrectly into the occluded region of the larger crater. Incorrect projection into occluded region of crater. Correct projection. 2830.pdf
47th Lunar and Planetary Science Conference (2016)
jection must be accounted for, and a unique elevation assigned to each one. . Among this set of surface points, the points also visible on the input raw image must be established. Occluded areas in the raw image must either be left empty in the orthophoto or taken from image(s) in which the area  is visible. In the absence of occlusion, the latitude-longitude coordinates on the target body of a pixel projected from the raw image should match to within a very small tolerance the coordinates of the pixel's projection (Figure 3). Explicitly, if: P1=(θ1,η1) is the (latitude, longitude) coordinate for the image plane projection of point P on the target, and P2=(θ2,η2) is the equivalent coordinate for the projection plane of point P, then:    ║P1 - P2║2 < ε  The value of ε is chosen so that it is large enough to filter out differences due to statistical noise, yet small enough to catch most of the occlusions. It should depend upon the resolution of the DEM [6] being used, as well as the image resolution. An exact formula for ε is under evaluation. The ║.║2 operator represents the Euclidean distance norm, but any norm will suffice.   We used this criteria to determine occluded areas in the orthophoto shown in Figure 4. Occluded pixels are green. Future Work: We are evaluating different formulas for ε in the method described above. Our ultimate goal is to develop an algorithm that is robust enough to deal with occlusion in the domain of close range images taken by a rover on the surface of a planet or asteroid, as well as satellite images. Currently we are examining multi-view depth map estimation (MVDE) approaches to the occlusion problem. An MVDE  method is presented in [7] which uses the Binocular PatchMatch algorithm [8] applied to an image sequence. The Binocular PatchMatch Algorithm extends the original PatchMatch method [9] to find accurate and optimal supporting images. References: [1] Novak, K. (1992) Photogramm. Eng. Remote Sens., 58(3), 339-344. [2] Kestay, L., et al. (2014) LPS XLV, Abstract #1686. [3] Anderson, J.A. (2013) LPS XLIV, Abstract #2069. [4] Karras, G.E., et al. (2007) Photogramm. Eng. Remote Sens., 73(4), 403-411. [5] Edmundson, K.L., et al. (2015) LPS XLVII (this conference), Abstract #1376. [6] Barker, M.K., et al. (2015) Icarus, in press, [online at http://dx.doi.org/10.1016/j.icarus.2015.07.039]. [7] Zhu, Z., et al. (2015) ISPRS J. Photogramm. Remote Sens., 109, 47-61. [8] Bleyer, M., et al. (2011) BMVC, 11, 1-11. [9] Barnes, C., et al. (2009) ACM Transactions on Graphics-TOG, 28(3),  p. 24.  Figure 3: Image projection in the absence of occlusion.  Figure 4: Orthographic projection of Carlini crater on the Moon. Occluded pixels are colored green. 2830.pdf
47th Lunar and Planetary Science Conference (2016)
