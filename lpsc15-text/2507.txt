 A SEMI-RIGOROUS SENSOR MODEL FOR PRECISION GEOMETRIC PROCESSING OF MINI-RF BISTATIC RADAR IMAGES OF THE MOON. R. L. Kirk1, J. M. Barrett1, D. E. Wahl2, I. Erteza2, C. V. Jackowatz2, D. A. Yocky2, S. Turner3, D. B. J. Bussey3, G. W. Paterson3, 1Astrogeology Science Center, U.S. Geological Survey, 2255 N. Gemini Dr., Flagstaff AZ 86001 (rkirk@usgs.gov), 2Sandia National Laboratories, Albuquerque, NM 87185, 3The Johns Hopkins University Applied Physics Laboratory, Laurel, MD 20723. Introduction: This abstract is one in a series [1-5] describing our development of techniques for radargrammetry (analogous to photogrammetry but taking account of the principles by which radar images are formed) and their application to mapping the Moon with Mini-RF images. Our overall goals are to use radar stereopairs to produce digital topographic models (DTMs) of medium resolution and broad coverage, and to control and orthorectify (project onto an existing DTM) images to produce image maps and mosaics with greatly improved positional accuracy. This abstract describes our approach to processing bistatic observations, building on the initial steps reported last year [5].  These observations are of tremendous scientific interest as part of the overall Mini-RF program of searching for ice deposits at the lunar poles [5,6] because the variation of signal strength with the phase angle between transmitter and receiver may distinguish between coherent backscatter in ice [8] and diffuse scattering by blocky surfaces [9]. By controlling and rectifying these observations we enable the quantitative analysis of radar-scattering properties on a point-bypoint basis with the more extensive monostatic radar images and other remote sensing data such as optical and thermal images and altimetry on a pixel-by-pixel basis. Source Data: NASA's Mini-RF investigation consists of two synthetic aperture radar (SAR) imagers for lunar remote sensing: the "Forerunner" Mini-SAR on ISRO's Chandrayaan-1 [6], and the Mini-RF on the NASA Lunar Reconnaissance Orbiter (LRO) [7], which carried out monostatic observations from 2009 until its transmitter failed in December 2010.  After this, the bistatic observations analysed here were obtained by LRO receiving S-band (12.6 cm wavelength) signals transmitted from the Arecibo Observatory [10]. Several tens of bistatic observations have been obtained to date, covering both polar and (as a baseline for possible detection of polar ice) nonpolar targets. Monostatic Mini-RF observations were processed by Vexcel Corporation into Level 1 (range-azimuth, where azimuth refers to distance along the flight track) and Level 2 (map projected) formats [11]. Bistatic observations are processed by Sandia National Laboratory [12].  Bistatic products delivered to the NASA Planetary Data System (PDS) to date use a grid referenced to the spacecraft trajectory in a complex way; companion files were provided to give the latitude and longitude of each pixel.  A first step toward precision geometric processing of the bistatic images [5] was to regenerate them in the Oblique Cylindrical projection used for monostatic Level 2 products.  The result is very similar visually, but lat-lon coordinates can now be calculated by a simple set of map projection equations, simplifying analysis.   Technical Approach and Methodology: The monostatic and bistatic radar images described above all contain positional offsets caused by errors in the spacecraft trajectory used in processing, plus parallax caused by topography (Fig. 1).  Our goal is to correct these errors and distortions.  The essential tool is a sensor model: a mathematical and software model capable of computing ground coordinates for a given image line-sample and vice versa.  In practice, the model can be divided into two steps:  (a) inverting the initial processing to recover the fundamental radar observables (range, and Doppler shift at a specified time) for an image pixel, and (b) determining where a feature with this range and Doppler shift should be located.  The opportunity to achieve precision georeferencing comes in the second step, where we can solve for an improved estimate of the spacecraft trajectory that brings the image into best registration with neighboring images and base data such as LOLA altimetry [13] (i.e., geodetic control) and project the data onto a detailed topographic model of the target (orthorectification).   Our bistatic sensor model is implemented in the USGS ISIS system [14] and uses a version of the ISIS bundle adjustment program jigsaw [15] for the control calculation.  The resulting workflow for precision products is analogous to that for monostaic MiniRF images [4].  The devil, as ever, is in the details.  Figure 1.  Overlay of LRO Mini-RF bistatic image of Cabeus crater (top center) and environs on a mosaic of east-looking monostatic images.  Circles show the misalignment of corresponding craters by several km between the uncontrolled east-looking (blue), west-looking (green) and bistatic (red) data products.  Geodetic control and orthorectification will reduce the misalignment to subpixel levels, permitting detailed comparison.  Polar Stereographic projection, South Pole at bottom, 330° E longitude toward top, grid spacing 5° (lat) by 15° (lon). Monostatic verus Bistatic:   The two types of radar observations are defined by their geometry.  In both cases, the observed quantities are the range to a surface point and its Doppler shift (which is proportional to the time derivative of range) at given point.  The difference is that for monostatic radar the transmitter and receiver are at the same location and range thus refers to distance from this point; the points with the same range lie on a sphere centered on the spacecraft (Fig. 2a).  For bistatic  observations, range is the total distance from transmitter to ground to receiver, and a given range thus defines an ellipsoid with transmitter and receiver at the foci (Fig. 2b).  The Doppler shift is proportional to the derivative of the range and is modified accordingly.  Though fundamental, these differences do not significantly change the operation of the sensor model. The formatting of the image data turn out to have a much larger impact on the sensor model design.  For the Mini-RF monostatic observations, each Level 1 image line represents an equal increment in time and contains those features that  were observed at zero Doppler shift (i.e., at minimum range, or directly to the side of the spacecraft) at that time.  The image labels contain the coefficients of polynomials that can be used to convert sample number to range.  Our initial model of the geometry of the bistatic observations [5] went astray by following this monostatic example too closely.  Figure 2a.  Cartoon illustrating the geometry of monostatic radar imaging.  Features are located in terms of their range from the spacecraft and Doppler shift at the time of observation.  Range (blue sphere and Doppler (green cone) surfaces intersect in a circle (red).  This intersects the planetary surface at two points, only one of which is illuminated.  As discussed in text, monostatic radar images are typically obtained by viewing perpendicular to the trajectory (near zero Doppler shift) rather than "squinted" as shown here.    Figure 2b.  Geometry of  bistatic radar observation.  "Range" is the total distance from transmitter (on Earth) to ground to spacecraft so defines an elongated ellipsoid (blue).  Doppler shift involves both transmitter and receiver motion but still defines a cone (green). The key factor for modeling the bistatic observations turns out to be that they are obtained at nonzero squint angle, i.e., with the radar antenna aimed ahead or behind rather than directly to the side of the spacecraft trajectory.  Squinting is equally possible for monostatic radar observations but is seldom used in practice.  For Mini-RF bistatic observations, squinting is essential to observing targets of geologic interest (polar craters and their low-latitude analogues) at specific phase angles.  Modeling the squint is critical to precision geometric processing because topographic parallax always occurs along the line between a surface feature and the location of the radar when it was observed.  For (unsquinted) bistatic images this is perpendicular to the flight track, but for squinted images parallax distortions are diagonal. A Semi-Rigorous Sensor Model:  The simplest conceptual approach to a radar sensor model would be to use the trajectory and surface models that were used in making the original image to back-calculate the time, range, and Doppler shift at which a pixel was observed, and then use an updated trajectory and better topographic model to project the pixel onto the ground in a more accurate location.  Unfortunately, the ISIS system is not designed to facilitate this kind of "double bookkeeping" of trajectory or surface models. We therefore divide our analysis of Mini-RF bistatic images into a preprocessing phase, in which we fit polynomial models to key variables (time, range, and  Doppler shift) calculated from the original trajectory, followed by a processing phase in which we use these fits to approximate the observables and then rigorously compute surface coordinates based on an updated trajectory and detailed surface.  This approach is a practical hybrid between rigorous (physicsbased) and non-rigorous (based purely on approximating functions) sensor models. Preprocessing:  This phase begins with calculation of the time at which each pixel is closest to the antenna boresight axis, as defined by the trajectory and pointing history of the spacecraft that were used to form the image and the latitude, longitude, and (assumed zero) elevation of the pixel.  This time is the average of the (relatively short) period over which a given ground feature is observed, and the spacecraft positon defines the direction in which parallax distortions operate.  Next, we calculate the range and Doppler shift for each pixel at its time of observation, still based on the nominal trajectory.  We then fit low-order polynomials to represent observation time as a function of image sample and line, range as a function of sample and time, and Doppler shift as a function of sample and time.  The fit for time is quadratic in sample but linear in line number, so it can be inverted to give the line at given sample and time.  For convenience we also fit a polynomial for sample at given range and time.  With these functions, we can calculate from line-sample to time-range-Doppler coordinates or the reverse as needed, with a typical precision of thousandths of a pixel. or better  The final step of preprocessing is to store the polynomial coefficients in the image labels and remove the map projection information (which was crucial to establishing them) so that ISIS henceforth treats the image as a Level 1 (image with known sensor model) rather than Level 2 (map projected)  product. Radargrammetric Processing:  To calculate from image to ground, the sensor model uses the polynomial fits to approximate time, range, and Doppler shift for a given pixel.  A rigorous (but iterative) calculation is then performed to determine where the locus of given range and Doppler shift intersects the planetary surface.  For the reverse transformation, range and Doppler shift of a ground point are calculated rigorously based on the spacecraft trajectory, at a guessed time of observation.  The time is then iteratively adjusted until the rigorous calculation and the polynomials give the same range and Doppler shift at the same line and sample.  To make the control adjustment by jigsaw possible, we also provide the means to calculate range and Doppler errors for a ground point at fixed time and the partial derivatives of these errors with respect to the spacecraft positon and velocity. Status and Future Work:  We are currently testing the sensor modeling approach described here on bistatic observations of Cabeus crater (Fig. 1) and will show pixel-bypixel comparisons of precision registered monostatic and bistatic polarimetric images in our presentation.  In order to make such comparisons possible for the full set of Mini-RF bistatic observations, we are working to define a new archival data format that will contain all the metadata necessary for our analysis, and to finalize a set of ISIS tools for preprocessing and radargrammetric processing of the bistatic data. References: [1] Kirk R. L. et al. (2010) LPS 41, 2428. [2] Kirk R. L., et al. (2011) LPS 42, 2392. [3] Kirk R. L., et al. (2012) LPS 43, 2772. [4] Kirk R. L. et al. (2013) LPS 44, 2920. [5] Kirk, R.L., et al. (2014) LPS, XLV, 2548. [6] Spudis P. D. et al. (2009) Curr. Sci. 96, 533. [7] Nozette S. et al. (2010) Space Sci Rev, 150, 285. [8] Hapke B. and Blewett (1991) Nature 352, 46. [9] Nelson R. M. et al. (2000) Icarus 147, 545. [10] Bussey D. B. J. et al. (2013) LPS 44, 2816. [11] Reid M. (2010) PDS Data Product SIS for Mini-RF, MRF-4009, February 25 2010. [12] Wahl D. E., et al. (2013) Proc. SPIE 8394, 83940D. [13] Smith D. E. et al. (2009) SSR 150, 209. [14] Anderson J. A. et al. (2004) LPS XXXV, 2039. [15] Edmundson K. L. et al. (2012) IAPRS 1(4), 203.  