2208.PDF
PYTHON FOR PLANETARY DATA ANALYSIS.  J.R. Laura, T. M. Hare, L.R. Gaddis, R.L. Fergason, Astrogeology Science Center, U.S. Geological Survey, 2255 North Gemini Drive, Flagstaff, AZ, 86001, jlaura@usgs.gov.Introduction:  Following our earlier publication onthis topic [1], we continue to see increased utilizationof the Python programming language by the planetaryscience community. A cursory search of the LPSCabstract archives shows a small, yet increasing numberof abstracts explicitly making mention of access tounderlying libraries via Python [e.g., 2, 3], thedevelopment of data processing capabilities withinPython [e.g., 4-8], or the development of analyticsolutions [e.g., 9-14]. These abstracts offer concreteexamples of Python usage for processing and workingwith planetary data. We attribute this increase to theease of use, readability, and portability of Python [1] asa scientific computing language. Python is commonlyapplied to High Performance Computing tasks and inthe prototyping and development of Graphical UserInterfaces, in continuing to leverage legacy code bases.This abstract reports our efforts to continue to integratePython into our workflows and highlights additionaluse cases of potential benefit across the planetaryscience community. High Performance Computing: Planetary datavolumes are increasing rapidly due to increased dataacquisition efforts associated with recent and newmissions, improved spatial, temporal, and radiometricsensor resolutions, and increasingly complex processmodels generating ever increasing derived products[e.g., 15]. At current and future data sizes, tractableanalysis requires either quantitative, repeatablemethods of data reduction or the utilization of HighPerformance Computing (HPC) resources. Since thepublication of the Atkins report [16], considerableresearch effort and funding has been invested in thedevelopment of Cyber Infrastructure (CI) projects.This suggests that the larger research community hasavoided large-scale reduction and embraced HPCutilization. CI is the multi-tiered integration of HPChardware embodied by distributed computingresources, "Big Data" sets, scalable processingcapability, and collaborative, cross-domain researchteams. Within the context of CI, Python is ideallysuited to support the development of scalable highperformance algorithms and the deployment of tools toreduce the complexity of HPC utilization that is withinthe CI middleware layer[22].At USGS Astrogeology, we have utilized Pythonfor the automated generation and submission of HPCjobs (e.g., Portable Batch System scripts) for thecreation of Mars Odyssey Thermal Emission ImagingSystem (THEMIS) derived imagery [23] and thecreation of rendered and animated 3D flyovers, as afull stack development environment to create RESTfulservices to expose underlying computational librariesthrough web based interfaces [18], and in utilizingHPC resources through the IPython notebook interfacefor proof-of-concept exploratory, big data analysis ofthe Kaguya Spectral Profiler data set [e.g., 19].Scripted job submission has provided an easy-to-useinterface for requesting and using HPC resources as ifthey are a local computer script. The development of aRESTful web interface to an analytical library providesthe capability to hide the utilization of HPC resourcesfrom the end user, significantly reducing complexity.Finally, the use of IPython notebooks and a computingcluster for many-core exploratory data analysis hasprovided an ideal interactive environment for thedevelopment of metrics for use in larger scaleautomated analysis methods1. For the development of parallel, scalablealgorithms Python offers three primary tools. First, thebuilt-in multiprocessing module is ideal for SymmetricMultiprocessing (SMP) machines (e.g., desktopcomputers) where a single shared memory space isadvantageous. This type of parallel computation isoften used when processing large raster datasets.Second, vectorization, supported by the NumericalPython (NumPy) library, provides significant speedupsfor vector or matrix based computation. Image andspectral data processing are primary applications ofthis type of serial performance improvement technique.Finally, The Message Passing Interface (MPI) forPython (mpi4py) package offers Python native accessto the MPI standard. More complex parallelizationefforts, such as spatially constrained optimization, cansignificantly benefit from higher levels ofcommunication across a highly distributed system. We continue to identify use cases for highperformance data storage formats, such as use of theHierarchal Data Format (HDF5) for the storage ofphotogrammetric control networks and complex modeloutput such as the multilayered thermal-diffusionmodel (KRC model [17]). In conjunction with Pandas,a Python library originally developed for robust bigdata quantitative financial analysis, there have beensignificant data storage reductions (due toco mp r e ss i on ) a n d a n a ly t i c a l pe r f o rm a nc eimprovements (due to robust underlying algorithms).Future work will focus on providing concurrent access1 See http://tinyurl.com/q76qkod for an example2208.pdf
46th Lunar and Planetary Science Conference (2015)
to these data structures in HPC environments forscalability testing. Legacy Code Bases: The redevelopment of anexisting code base in a new language can be a costly,ill-advised endeavor due to the aggregate time alreadyinvested in the original development and the difficultyin regression testing between implementations. To thatend, f2py and the Python native CTypes librariesprovide two invaluable tools for wrapping legacyFortran and C code, respectively. While the complexityof the wrapping scales with the complexity of theunderlying code, we note that most Fortran subroutinesare immediately wrappable with simply the definitionof a few variable types. Likewise, wrapping of a C (orC++) library requires minimal additional development.Assuming that a complex legacy system can be splitinto smaller components, code portability can bereadily realized. The additional development can befocused external to the algorithm logic, helping toreduce the potential to introduce bugs.While f2py and CTypes frequently find applicationworking with legacy systems, significant benefit canbe realized with actively developed code bases. In thecontext of an HPC system, the ability to write andwrap small algorithm components in low level, highperformance languages, while still maintaining rapiddevelopment via a higher level language is essential.This is primary reason why Fortran, C, and Python areconsidered dominant HPC languages. In practice, wemost frequently apply this approach when performinga sequential operation for which vectorization isunsuited.IPython / Jupyter: The IPython project [20],recently renamed to Jupyter, is composed of a local,lightweight web server and browser-based interfacewhich allows for development, inline images, andLaTeX or MarkDown structured mathematics. Inaddition to Python, IPython also supports otherenvironments and languages, for example Julia,Haskell, Cython, R, Octave (a MatLab alternative),Bash, Perl, and Ruby. We find extensive application ofIPython notebooks for exploratory data analysis in thecontext of model development and validation, localand remote data access testing, for example in readingcomplex binary data structures, GUI developmentwhere an interactive window is spawned from within aweb browser, interfacing with our HPC resources, andfinally portability of analytical methods and results tocollaborators. For this final use case, shipment of asingle, Javascript Object Notation (JSON) file and anysupplemental data files, e.g. Planetary Data System(PDS) image file, is all that is required for completereproducibility. Each instance of an IPython notebookis run local to a single desktop computer and the newJupyter project offers the ability to run a single accessserver to a distributed set of users. Graphical User Interface Development: Pythonprovides an ideal platform for the development of highend Graphic User Interfaces (GUIs), as well as standalone visualizations.  Libraries such as PyQt, PySide,WxPython, and Tkinter offer access to robust GUIdevelopment libraries.  At USGS Astrogeology, wehave developed multiple cross-platform, stand-aloneGUI interfaces in pure Python using PySide to call theQt4 library.  These tools are rapid to develop, robust tomaintain, and relatively straight-forward to deploy.Conclusion: Use of Python for scientificcomputing and data processing in planetary science iswell underway.  While research projects at USGS arenow using Python tools, the tools generally are notmade public for more general use.  We are currentlyexploring ways to integrate both existing and newPython software into the USGS Astrogeology ISISsoftware [e.g., 21 and references therein] so that moregeneral planetary applications can be realized.References: [1] Laura et al., 2014, LPSC XLVAbs. #2226. [2] Leone et al., 2014, LPSC XLV Abs.#2058. [3] Sylvest et al. 2014, LPSC XLV, Abs. #2309[4] Neakrase, et al., 2013,LPSC XLIII, Abs. #2557. [5]Cikota et al., 2013, LPSC XLIV, Abs. # 1520. [6] Hareet al., 2014, LPSC LXV, Abs. #2474. [7] Lust andBritt, 2014, LPSC LXV, Abs. #2571. [8] Watters andRadford, 2014, LPSC XLV, Abs. #2836. [9] Laura etal., 2012, LPSC XLIII, Abs. #2371. [10] Levengoodand Shepard, 2012, LPSC XLIII, Abs. #1230. [11]Gaddis et al., 2013, LPSC XLIV, Abs. #2587 [12]Oosthoek et al., 2013, LPSC XLIV, Abs. #2523 [13]Calzada-Diaz  et al., 2014, LPSC XLV, Abs. #1424.[14] Narlesky and Gulick, 2014, LPSC XLV, Abs.#2870. [15] Gaddis et al., USGS Open-File Report2014-1056. [16] Atkins et al. (2003), RevolutionizingScience and Engineering Through Cyberinfrastructure.[17] Fergason et al., this meeting. [18] Laura, J. et al.,2014, Development of a restful api for the pythonspatial analysis library(2014)., 61st Annual NARSC.[19] Gaddis et al., this meeting. [20] PÃ©rez, F andGranger, B.E., 2007, Comp. Sci. and Engin., 9:21-29,doi:10.1109/MCSE.2007.53. [21] Keszthelyi et al.,2013, LPSC XLIV, abs. #2546. [22] Wang et al., 2013,CyberGIS: Blueprint for integrated and scalablegeospatial software ecosystems. IJGIS,  [23] Fergasonet al. LPSC LXIV Abs. # 2822. 2208.pdf
46th Lunar and Planetary Science Conference (2015)
