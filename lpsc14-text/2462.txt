 B A GEOMETRIC PREPROCESSING AND AUTOMATED PATTERN MATCHING TECHNIQUES FOR PLANETARY PHOTOGRAMMETRIC MAPPING.  R. A. Saleh, Astrogeology Science Center, U. S. Geological Survey (2255 N. Gemini Drive, Flagstaff, AZ 86001, USA, rsaleh@usgs.gov).   Introduction: While significant successes have been achieved in automating photogrammetric procedures for Earth surface mapping and cartographic production, there still exists a need for automated photogrammetric procedures in planetary mapping.  Pattern matching is a core function in such automation as it is the basis of getting input data necessary to control overlapping images.  State-of-the-art pattern matching in planetary mapping is not ideal.  As a result, the need for a human operator to intervene manually limits the size of projects that can be considered for planetary cartographic production while keeping the cost realistic.  There is, however, a hope in applying automated methods from Earth mapping, which have had considerable success.  Saleh and Kirk [1] described a range of matching techniques that might be helpful in increasing success rates in automated pattern matching used in the Integrated Software for Imagers and Spectrometers, ISIS, of the USGS [2].  In this abstract, after an brief overview of pattern matching in ISIS, we describe current work focusing on geometric preprocessing that aims at setting the search space between the pattern and the "true" match within two overlapping images.  In this ongoing work, we hypothesize that geometric misalignment and/or distortion between overlapping images are potential reasons for failure to retrieve a correct match.  Figure 1 shows cases relating the calculated search range and the potential for finding a true match.            Figure 1. A. Pattern is inside calculated search window. B. Pattern is outside calculated search window. We intend to conduct tests to examine the impact of misalignment on match success rates, and to quantify this impact.  Based on these tests, we will implement modifications to the software, including dynamically modifying the range of the search space.  Another possible change is implementing a rigorous image-to-image transformation to calculate a more precise first approximation of the location of the true match.  Upon implementing these changes, we expect that match success rate would improve mainly with images that have similar radiometric qualities but with greatest geometric misalignment.   Current Status: The current level of manual validation and editing of cartographic deliverables is quickly making globally-controlled products of modern planetary missions a practical impossibility.  The automated matching functions demonstrate a rate of failure that call into question the assumption of SPICE accuracy and the close alignment of overlapping images.  The other potential reason for these failures is the accuracy of the pattern matching techniques used in ISIS.  Current automated matching results require substantial manual editing of the list of candidate matches to eliminate blunders, which is very costly in comparison to automated processing.  As size and complexity of image datasets increase, due to the number of different imaging systems, different illumination conditions, etc., the amount of needed manual editing makes controlling these datasets cost prohibitive.   Pattern Matching in ISIS: In general, matching techniques can be classified into several categories [4,5].  These include spatial domain categories, such as areabased, like cross-correlation (CC), mutual information (MI), and least squares method (LSM); and feature based methods, e.g.,  SIFT and SURF. Another category can be applied in the frequency domain, such as Fourier transformation. A third category includes context-based methods, which are outside the scope of this work.  While significant successes have been achieved in automating production-viable terrestrial photogrammetric systems using a variety of these matching techniques, no similar successes can be claimed in the planetary domain.  The underlying matching technique currently used in ISIS is CC, which models the difference between pattern patches as linear functions of the intensity values combined with two-dimensional integer shift.  This shift is typically one pixel at the search direction line, and once exhausted, the search shift to the next line in the search direction.  ISIS does not model geometric and radiometric differences during matching, except crudely at the level of the whole matching patch.  These differences potentially affect success, efficiency and accuracy of matching; hence geometric rectification and radiometric filtering are applied to partially compensate for these differences.  Geometric Preprocessing: ISIS comprises object oriented classes that handle spacecraft exterior position and orientation, image measurements, sun angles, known sensor parameters, and precision time readings.  These and other data are captured within the Space Planet Instrument C-matrix Events (SPICE) files (or "kernels") as maintained by the NASA Navigation and Ancillary Information Facility (NAIF) [3].  ISIS has tools for SPICE kernel management and requests for spacecraft-specific   data at a given spacecraft ephemeris time using sensor models unique for each mission.  One of the main functions is setting a look direction vector for a sensor and computing its intersection with the target body.  A successful intersection results in ground coordinates, which in turn are used to compute a look direction vector back to the spacecraft in a different position.  This ISIS capability allows calculation of approximate location of the same pattern in overlapping images acquired from different positions.  The specific functionality in ISIS is coined as "fast geom", which is accessed by programs such as "qnet", "pointreg", and "autoreg".  As shown in Figure 2, ISIS transfers the four corners of the pattern window that represents the reference target from one image to the corresponding locations in the match search space in the overlapping image from different orbits.   Figure 2. Calculation of the search window of the target match pattern in ISIS based on the sensor model. This transformation is achieved using sensor model and a DTM. A typical size of search window is over a hundred pixels across and the limited number of rigorously transformed points may leave significant perspective distortions in the images.  The accuracy of this transformation is assumed to be dependent on: A) the accuracy of SPICE data of the overlapping images, B) the initial orientation of overlapping images in relation to each other, and C) the accuracy and fidelity of the DTM.  Assuming that the SPICE data are accurate, the images are geometrically aligned, and the surface model is reasonable for the given images, locating the corresponding target in the overlapping image would be achieved successfully using ISIS pattern matching routines.  In reality however, we encounter highly oblique images, and/or images taken from rotated viewpoints (relative to each other) that as a result are highly misaligned.  In addition, accuracy of the surface model can be largely approximate or noisy, if it exists at all beyond being considered as a plane or spheroid.  Another factor depends on how rugged the target area in the surface is. This results in different reflectance from different angles, thus higher match failures. Approach:  This project involves extensive testing using real image datasets, of current space missions, such as LROC NAC, HiRISE, and THEMIS, among possible others.  The specific images are selected based on two independent geometric variables. First is the accuracy level of SPICE data, and second, the alignment between two overlapping images acquired from different positions.  These two variables yield four different cases of geometries: Case 1: Good Spice, Good Alignment; Case 2: Good Spice, Bad Alignment; Case 3: Bad Spice, Good Alignment; Case 4: Bad Spice, Bad Alignment.  Figure 3 depicts the image footprints of only Cases 1 and 4 for clarification.  The target number of images is 20-32 pairs, with 5 to 8 pairs for each one of the four cases.  Figure 3. Effects of SPICE and Alignment in Cases 1 and 4 The test would evaluate the impact of geometric misalignment and/or distortion between the overlapping images in producing a search range that would miss the correct match.  The calculated search range would be recorded and visually identified on the search image.  At the same time, the true match would also be visually identified and determined if it falls within the search range, and if outside, by how many pixels.  A numerical trend would then be established to correlate the geometric variables against distance from the search limits.  Future Work: Based on these tests, we will implement necessary modifications to address these cases, including: A) dynamically adjusting the range of the search space; B) implementing a rigorous image-toimage transformation to calculate a more precise first approximation of the location of the true match; and C) a combination.  Upon implementing these changes, we expect that matching success rate would improve mainly with images that have similar radiometric qualities but with greatest geometric misalignment (as a result of these modifications).  We expect to discuss these results in our meeting presentation. References: [1] Saleh, R. A. (2013), LPS XLIV Abstract # 3008. [2] Keszthelyi, L., et al. (2014) this volume. [3] Acton, C. H., et al. (1996) Planet. Space Sci., 44(1), 65-70. [4] Kim, T. and Y. J. Im, 2003 IEEE Transactions on GRS,  41, Issue: 5,  pp. 1111-1117. [5] Lemmens, J. P. M., 1988. International Archives of Photogrammetry and Remote Sensing, 27(B8), 11-23. 