 Apollo Metric Imagery Registration to Lunar Orbiter Laser Altimetry. Ara V Nefian1,2, Brian Coltin1 and Terry Fong2, 1Carnegie Mellon University, 2NASA Ames Research Center, MS 245-3, Moffett Field, CA, USA (ara.nefian@nasa.gov) In this paper, we address the LIDAR to image coregistration problem with the goal of coregistering images from the Apollo metric camera to data from the recently deployed Lunar Reconaissance Orbiter's Lunar Orbiter Laser Altimeter (LOLA). Our novel approach requires no prior knowledge of the surface topographic features or craters, and uses all the available LIDAR and image data including the camera and Sun position at the time the images were captured. We first convert the LOLA data to a synthetic image by inputting measured surface normals and estimated Sun and spacecraft positions into a lunar reflectance model. Then, we find a planar homography which aligns the synthetic image to the actual image using the Gauss-Newton algorithm. However, the GaussNewton algorithm is susceptible to local minima, and a naive, straightforward application fails. Instead, we first apply GaussNewton to lower-resolution images which smoothes over local minima. Then, we refine the transformation on successively higher-resolution layers of the image pyramid. Apollo Metric Camera and Lunar Orbiter Laser Altimetry Data The Apollo Metric Camera (AMC) flew aboard the lunar command module of the Apollo 15 mission [1] and captured orbital images on film that were recently scanned at 10m/pixel resolution with approximately 22,000 × 22,000 pixels per image. The laser data is acquired from the Lunar Orbiter Laser Altimeter (LOLA), an instrument of the Lunar Reconaissance Orbiter (LRO). The LOLA splits a laser into five parts to take five distance measurements to the lunar surface, arranged in a cross shape. Each set of five measurements is called a shot. Each of the five laser beams illuminates a 5 m diameter spot on the moon's surface. The LRO flies above the surface of the Moon in a polar orbit, taking LOLA shots directly beneath it as it moves. Successive shots are approximately 56 m apart, and each sequence of shots from the same orbit forms a track [2]. Alignment Uncertainty in Apollo 15's pose affects the image's pose relative to all of the LIDAR tracks, while error in the LRO's position occurs on a per-track basis. In our approach we form a synthesized image from the LOLA tracks and match it to the Apollo image using a Gauss-Newton method. Forming Synthesized Images To align the LOLA tracks to the Apollo images, we estimate the lunar reflectance R for each LOLA shot to form a synthetic image. The Lunar-Lambertian reflectance is a function of the angle of incidence of light, which depends on the angle to the sun and the surface normal. The surface normal is computed by adding the normals from each available triangle in the LOLA shot and normalizing the result. Some triangles' normals may not be available since LOLA does not always successfully return five surface readings. Given the surface normal and the vector from the surface to the sun, we compute the expected reflectance with the photometric equation presented in [3], as R = 2L(α)µ0/(µ0 + µ) + (1− L(α))µ0 where µ0 is the cosine of the incidence angle between the vector to the sun and the surface normal, µ is the cosine of the emission angle between the surface normal and vector to the spacecraft, θ is the angle in degrees between the spacecraft and sun from the lunar surface, and L(α) = 1.0−0.019α+2.42∗ 10−4α2 − 1.46 ∗ 10−6α3 is the limb darkening factor that depends on the phase angle α. The synthetic image along each LOLA track is then a product of the reflectance and a constant factor, γR. The value of γ depends on two factors: the parameters of the camera that took the image, and the properties of the reflecting surface. The albedo of the lunar surface varies, particularly between the flat, low-lying maria and the highlands, but it is locally consistent. Parameter Estimation: Gauss Newton Algorithm Our goal is to find argmin MS(M) = argmin M∑ iei(M) 2, where ei(M) = I (Mpi) − γRi is the error between a single LOLA shot's synthetic image and observed image given a transformation homography M . The true error in the satellites' positions cannot be accounted for with a planar homography, since the surface of the moon and the LRO's motion are both non-planar. However, we have found that planar homographies are an effective approximation across limited areas. Minimizing this objective function is a non-linear least squares problem. A common tool for solving such problems is the Gauss-Newton algorithm, a variant of Newton's method which doesn't require the computation of second derivatives. Search Over the Image Pyramid The Gauss-Newton algorithm, like Newton's method, is highly susceptible to local minima. In our problem, the LOLA tracks begin highly misaligned, and a naive application of GaussNewton will converge to nearby local minima rather than the global minima. To prevent this, we first search on downsampled, lower-resolution layers of the image pyramid. By downsampling we find only a coarse alignment, but the lower resolution image allows us to avoid local minima and coregister the tracks in the presence of large initial errors. Once a coarse alignment is found, we align the LOLA tracks on progressively higher resolution layers of the image pyramid using coarser alignments as starting points to avoid local minima.  2(a) Before Coregistration (b) After Coregistration Fig. 1. (a) shows the tracks' estimated reflectance (the synthetic image) against an Apollo 15 image with the original alignment (passing from top to bottom). (b) shows the synthetic image and the Apollo 15 image after coregistration. The LOLA tracks are delineated by two bright lines, and the synthetic image is shown as the color between the lines. Selected Results Figure 1 show the position of the LOLA tracks on an Apollo image both before and after finding a transformation. The red lines indicate the tracks, and the color between them indicates the expected luminence of the moon based on the surface normal, sun position and camera position. The initial error in both cases is large, as seen by the large mismatch between the color of the LOLA track and the background image. After Gauss-Newton on the image pyramid is applied, a successful transformation is found. The expected image intensity closely matches the actual intensity. Although our algorithm allows us to find general planar homographies from the track coordinates to image coordinates, in practice the transformations that are found are affine transformations. They have a large translational component and a slight rotational component. Conclusions and Future Work We have presented a novel algorithm that aligns orbital LIDAR data captured by a current lunar mission to orbital images taken with imprecise camera poses during the Apollo missions. The algorithm applies the Gauss-Newton method to determine the best homography between the actual image and a synthetic image obtained from the local surface normals using the Lunar Lambertian reflectance model. To avoid local minima and speed up computation the method is applied on an image pyramid. The algorithm has been successfully tested on large areas of the equatorial lunar surface. References [1] SJ Lawrence, MS Robinson, M. Broxton, JD Stopar, W. Close, J. Grunsfeld, R. Ingram, L. Jefferson, S. Locke, R. Mitchell, et al. The apollo digital image archive: new research and data products. In Proc of the NLSI Lunar Science Conference, volume 2066, 2008. [2] D.E. Smith, M.T. Zuber, G.A. Neumann, F.G. Lemoine, E. Mazarico, M.H. Torrence, J.F. McGarry, D.D. Rowlands, and J.W. Head III. Initial observations from the lunar orbiter laser altimeter(lola). Geophysical Research Letters, 37(18), 2010. [3] AS McEwen. A precise lunar photometric function. In Lunar and Planetary Institute Science Conference Abstracts, volume 27, page 841, 1996. 