1679.PDF
Apollo Metric Imagery Registration to Lunar Orbiter Laser Altimetry. Ara VNefian1,2, Brian Coltin1 and Terry Fong2, 1Carnegie Mellon University, 2NASA Ames Research Center, MS 245-3, Moffett Field,CA, USA (ara.nefian@nasa.gov)In this paper, we address the LIDAR to image coregistration problem with the goal of coregistering images fromthe Apollo metric camera to data from the recently deployedLunar Reconaissance Orbiter’s Lunar Orbiter Laser Altimeter(LOLA). Our novel approach requires no prior knowledge ofthe surface topographic features or craters, and uses all theavailable LIDAR and image data including the camera and Sunposition at the time the images were captured. We first convert the LOLA data to a synthetic image by inputting measured surface normals and estimated Sun and spacecraft positions into a lunar reflectance model. Then, we find a planarhomography which aligns the synthetic image to the actual image using the Gauss-Newton algorithm. However, the GaussNewton algorithm is susceptible to local minima, and a naive,straightforward application fails. Instead, we first apply GaussNewton to lower-resolution images which smoothes over localminima. Then, we refine the transformation on successivelyhigher-resolution layers of the image pyramid.Apollo Metric Camera and Lunar OrbiterLaser Altimetry DataThe Apollo Metric Camera (AMC) flew aboard the lunar command module of the Apollo 15 mission [1] and captured orbitalimages on film that were recently scanned at 10m/pixel resolution with approximately 22,000 × 22,000 pixels per image.The laser data is acquired from the Lunar Orbiter LaserAltimeter (LOLA), an instrument of the Lunar ReconaissanceOrbiter (LRO). The LOLA splits a laser into five parts to takefive distance measurements to the lunar surface, arranged in across shape. Each set of five measurements is called a shot.Each of the five laser beams illuminates a 5 m diameter spoton the moon’s surface. The LRO flies above the surface of theMoon in a polar orbit, taking LOLA shots directly beneath it asit moves. Successive shots are approximately 56 m apart, andeach sequence of shots from the same orbit forms a track [2].AlignmentUncertainty in Apollo 15’s pose affects the image’s pose relative to all of the LIDAR tracks, while error in the LRO’s position occurs on a per-track basis. In our approach we form asynthesized image from the LOLA tracks and match it to theApollo image using a Gauss-Newton method.Forming Synthesized ImagesTo align the LOLA tracks to the Apollo images, we estimatethe lunar reflectance R for each LOLA shot to form a syntheticimage. The Lunar-Lambertian reflectance is a function of theangle of incidence of light, which depends on the angle to thesun and the surface normal. The surface normal is computed byadding the normals from each available triangle in the LOLAshot and normalizing the result. Some triangles’ normals maynot be available since LOLA does not always successfully return five surface readings.Given the surface normal and the vector from the surfaceto the sun, we compute the expected reflectance with the photometric equation presented in [3], asR = 2L(α)µ0/(µ0 + µ) + (1− L(α))µ0where µ0 is the cosine of the incidence angle between the vector to the sun and the surface normal, µ is the cosine of theemission angle between the surface normal and vector to thespacecraft, θ is the angle in degrees between the spacecraft andsun from the lunar surface, and L(α) = 1.0−0.019α+2.42∗10−4α2 − 1.46 ∗ 10−6α3 is the limb darkening factor that depends on the phase angle α. The synthetic image along eachLOLA track is then a product of the reflectance and a constantfactor, γR. The value of γ depends on two factors: the parameters of the camera that took the image, and the properties of thereflecting surface. The albedo of the lunar surface varies, particularly between the flat, low-lying maria and the highlands,but it is locally consistent.Parameter Estimation: Gauss Newton AlgorithmOur goal is to findargminMS(M) = argminM∑iei(M)2,where ei(M) = I (Mpi) − γRi is the error between a single LOLA shot’s synthetic image and observed image given atransformation homography M . The true error in the satellites’positions cannot be accounted for with a planar homography,since the surface of the moon and the LRO’s motion are bothnon-planar. However, we have found that planar homographiesare an effective approximation across limited areas.Minimizing this objective function is a non-linear leastsquares problem. A common tool for solving such problemsis the Gauss-Newton algorithm, a variant of Newton’s methodwhich doesn’t require the computation of second derivatives.Search Over the Image PyramidThe Gauss-Newton algorithm, like Newton’s method, is highlysusceptible to local minima. In our problem, the LOLA tracksbegin highly misaligned, and a naive application of GaussNewton will converge to nearby local minima rather than theglobal minima. To prevent this, we first search on downsampled, lower-resolution layers of the image pyramid. By downsampling we find only a coarse alignment, but the lower resolution image allows us to avoid local minima and coregisterthe tracks in the presence of large initial errors. Once a coarsealignment is found, we align the LOLA tracks on progressivelyhigher resolution layers of the image pyramid using coarseralignments as starting points to avoid local minima.1679.pdf
45th Lunar and Planetary Science Conference (2014)
2(a) Before Coregistration (b) After CoregistrationFig. 1. (a) shows the tracks’ estimated reflectance (the synthetic image) against an Apollo 15 image with the original alignment(passing from top to bottom). (b) shows the synthetic image and the Apollo 15 image after coregistration. The LOLA tracks aredelineated by two bright lines, and the synthetic image is shown as the color between the lines.Selected ResultsFigure 1 show the position of the LOLA tracks on an Apolloimage both before and after finding a transformation. The redlines indicate the tracks, and the color between them indicatesthe expected luminence of the moon based on the surface normal, sun position and camera position. The initial error in bothcases is large, as seen by the large mismatch between the colorof the LOLA track and the background image.After Gauss-Newton on the image pyramid is applied, asuccessful transformation is found. The expected image intensity closely matches the actual intensity. Although our algorithm allows us to find general planar homographies from thetrack coordinates to image coordinates, in practice the transformations that are found are affine transformations. They havea large translational component and a slight rotational component.Conclusions and Future WorkWe have presented a novel algorithm that aligns orbital LIDAR data captured by a current lunar mission to orbital imagestaken with imprecise camera poses during the Apollo missions.The algorithm applies the Gauss-Newton method to determinethe best homography between the actual image and a syntheticimage obtained from the local surface normals using the Lunar Lambertian reflectance model. To avoid local minima andspeed up computation the method is applied on an image pyramid. The algorithm has been successfully tested on large areasof the equatorial lunar surface.References[1] SJ Lawrence, MS Robinson, M. Broxton, JD Stopar,W. Close, J. Grunsfeld, R. Ingram, L. Jefferson, S. Locke,R. Mitchell, et al. The apollo digital image archive: newresearch and data products. In Proc of the NLSI Lunar Science Conference, volume 2066, 2008.[2] D.E. Smith, M.T. Zuber, G.A. Neumann, F.G. Lemoine,E. Mazarico, M.H. Torrence, J.F. McGarry, D.D. Rowlands, and J.W. Head III. Initial observations from the lunarorbiter laser altimeter(lola). Geophysical Research Letters,37(18), 2010.[3] AS McEwen. A precise lunar photometric function. In Lunar and Planetary Institute Science Conference Abstracts,volume 27, page 841, 1996.1679.pdf
45th Lunar and Planetary Science Conference (2014)
